{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mporting essential libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data and test data\n",
    "Train_X=pickle.load(open('classificationX4','rb'))\n",
    "Train_Y=pickle.load(open('classificationY4','rb'))\n",
    "Test_X=pickle.load(open('classificationTest3','rb'))\n",
    "X=pickle.load(open('classificationTestx3','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping training and test data\n",
    "Train_X=np.expand_dims(Train_X, axis=-1)\n",
    "Test_X=np.expand_dims(Test_X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               3686500   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,687,241\n",
      "Trainable params: 3,687,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(50, 50, 1..., activation=\"relu\")`\n",
      "  \n",
      "G:\\anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "  \"\"\"\n",
      "G:\\anaconda\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Classifier model---The input is 50x50 matrix output is probability\n",
    "Classifier = Sequential()\n",
    "Classifier.add(Convolution2D(64,3,3,input_shape = (50,50,1),activation = 'relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "Classifier.add(Flatten())\n",
    "Classifier.add(Dense(output_dim=100,activation = 'relu'))\n",
    "Classifier.add(Dense(output_dim=1,activation = 'sigmoid'))\n",
    "Classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics=['accuracy'])\n",
    "Classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 12 samples\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.6538e-04 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.6813e-04 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.4266e-04 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.5588e-04 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.5750e-04 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.3838e-04 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.4097e-04 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9020 - val_loss: 3.3365e-04 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.3231e-04 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9020 - val_loss: 3.1971e-04 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.9755e-04 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.5915e-04 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.9510e-04 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.2339e-04 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.4809e-04 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.5521e-04 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 3.6724e-04 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 2.4465e-04 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 3.4443e-04 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0687 - acc: 0.9020 - val_loss: 2.9866e-04 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0685 - acc: 0.9020 - val_loss: 2.8850e-04 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 4.3273e-04 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 2.4610e-04 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 3.4735e-04 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.2398e-04 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.0730e-04 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.2250e-04 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.8986e-04 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 3.2477e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.8011e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.6791e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 2.7853e-04 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0683 - acc: 0.9020 - val_loss: 3.1522e-04 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0683 - acc: 0.9020 - val_loss: 2.3391e-04 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 2.8502e-04 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0685 - acc: 0.9020 - val_loss: 2.4444e-04 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0684 - acc: 0.9020 - val_loss: 2.6312e-04 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9020 - val_loss: 2.7088e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9020 - val_loss: 2.3929e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.6110e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.4445e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.4590e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9020 - val_loss: 2.3856e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0680 - acc: 0.9020 - val_loss: 2.3809e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.1790e-04 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.4047e-04 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.0856e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.3816e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 1.9691e-04 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.2404e-04 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 1.9985e-04 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.2275e-04 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9020 - val_loss: 1.6731e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0687 - acc: 0.9020 - val_loss: 2.3436e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0686 - acc: 0.9020 - val_loss: 1.8662e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0683 - acc: 0.9020 - val_loss: 1.8230e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0681 - acc: 0.9020 - val_loss: 2.0546e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0682 - acc: 0.9020 - val_loss: 2.3224e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0692 - acc: 0.9020 - val_loss: 1.6893e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0688 - acc: 0.9020 - val_loss: 2.5773e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 0.9020 - val_loss: 2.7815e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0699 - acc: 0.9020 - val_loss: 1.6497e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0695 - acc: 0.9020 - val_loss: 3.2720e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0710 - acc: 0.9020 - val_loss: 1.3835e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0703 - acc: 0.9020 - val_loss: 3.3466e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0755 - acc: 0.9020 - val_loss: 1.4933e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0798 - acc: 0.9020 - val_loss: 3.5513e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0773 - acc: 0.9020 - val_loss: 5.9953e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0704 - acc: 0.9020 - val_loss: 1.1655e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0748 - acc: 0.9020 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0894 - acc: 0.9020 - val_loss: 1.1849e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0960 - acc: 0.9020 - val_loss: 8.2037e-05 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0784 - acc: 0.9020 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1012 - acc: 0.9020 - val_loss: 5.8487e-05 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.0952 - acc: 0.916 - 0s 2ms/step - loss: 0.1091 - acc: 0.9020 - val_loss: 5.1222e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1191 - acc: 0.9020 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1400 - acc: 0.9020 - val_loss: 2.3707e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1076 - acc: 0.9020 - val_loss: 8.3706e-05 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1044 - acc: 0.9020 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1720 - acc: 0.9020 - val_loss: 0.0616 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1095 - acc: 0.9020 - val_loss: 2.9517e-05 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1609 - acc: 0.9020 - val_loss: 1.8810e-05 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1295 - acc: 0.9020 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.1233 - acc: 0.9020 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0898 - acc: 0.9020 - val_loss: 7.8010e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0738 - acc: 0.9020 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0840 - acc: 0.9020 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0874 - acc: 0.9020 - val_loss: 8.0149e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0884 - acc: 0.9020 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0851 - acc: 0.9020 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0761 - acc: 0.9020 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0735 - acc: 0.9020 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0711 - acc: 0.9020 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0694 - acc: 0.9020 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0706 - acc: 0.9020 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0704 - acc: 0.9020 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0697 - acc: 0.9020 - val_loss: 8.8308e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0700 - acc: 0.9020 - val_loss: 8.9497e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0731 - acc: 0.9020 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0722 - acc: 0.9020 - val_loss: 0.0011 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "history = Classifier.fit(Train_X,Train_Y,epochs=100,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction using test data\n",
    "Result=Classifier.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predicted data plotted against temperature\n",
    "plt.scatter(X,Result,s=10,c='red')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Probablity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "Classifier.save('Classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
